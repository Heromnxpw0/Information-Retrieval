{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit a summary (pdf) of the data, including the total number of articles, topics, number of articles per topic, percentage of unique words per topic, and percentage of stopwords per topic by Saturday (16/11/2024) at 11:59 PM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = [\"Artificial Intelligence\", \"Machine Learning\", \"Data Science\", \"Big Data\", \"Cloud Computing\", \"Bioinformatics\", \"Data mining\", \"Cybersecurity\"]\n",
    "cols = ['Topic', 'Articles per topic', r'% of unique words', r'% of stop words', 'Total number of words']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "cBffAgQsLSOW"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('data.json', 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ba7eb', 'sadam']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"ba7eb sadam\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "stats = pd.DataFrame(columns = cols)\n",
    "for topic in topics:\n",
    "    row = [topic, len(data[topic])]\n",
    "    freq = {}\n",
    "    count_stopwords = 0\n",
    "    total_words = 0\n",
    "    for article in data[topic]:\n",
    "        words = data[topic][article]['content'].split()\n",
    "        total_words += len(words)\n",
    "        for word in words:\n",
    "            if word in stopwords:\n",
    "                count_stopwords += 1\n",
    "            if word in freq:\n",
    "                freq[word] += 1\n",
    "            else:\n",
    "                freq[word] = 1\n",
    "    count_once = 0\n",
    "    for word in freq:\n",
    "        if freq[word] == 1:\n",
    "            count_once += 1\n",
    "    row.append(count_once / total_words)\n",
    "    row.append(count_stopwords / total_words)\n",
    "    row.append(total_words)\n",
    "    stats.loc[len(stats)] = row\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fpdf import FPDF\n",
    "class PDF(FPDF):\n",
    "    def header(self):\n",
    "        self.set_font(\"Arial\", size=12)\n",
    "        self.cell(0, 10, \"DataFrame Report\", ln=1, align=\"C\")\n",
    "\n",
    "pdf = PDF()\n",
    "pdf.add_page()\n",
    "pdf.set_font(\"Arial\", size=10)\n",
    "\n",
    "# Add DataFrame content\n",
    "for col in stats.columns:\n",
    "    pdf.cell(40, 10, col, border=1)  # Column names\n",
    "\n",
    "pdf.ln()  # Line break\n",
    "\n",
    "for index, row in stats.iterrows():\n",
    "    for cell in row:\n",
    "        pdf.cell(40, 10, str(cell), border=1)\n",
    "    pdf.ln()\n",
    "\n",
    "# Save to file\n",
    "pdf.output(\"dataframe.pdf\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
